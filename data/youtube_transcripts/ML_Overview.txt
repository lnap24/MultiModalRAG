okay uh so here we are welcome to the first in a series of three well four actually um machine learning uh kind of overview presentations um lectures so let's jump into the first one i apologize if i kind of cough along the way here still fighting through a little bit of a cold so here are the themes for this we're going to talk about the machine learning life cycle even though we've done that a little bit you know what are the conditions that are necessary for machine learning and then just like general kind of machine learning uh terms and phrases all right you'll see that we got this broken down into three sections so each success each week we'll go through a new section of this as we work through um kind of each one of the introductory components of machine learning but we're going to do it based off the phases that we have there and at the very end we're going to do a section just on evaluation because it's pretty important uh okay so let's keep going here all right so i'm trying to get me out of the way let me over here maybe zoom this in just a bit whoa too much all right here's my fingers it's better mechanism okay all right so first off um this this um uh this data science lifecycle down here is kind of a cartoonish version of the one that i'll present that i showed you guys already this is uh kind of the life cycle associated with uh software development all right and this is important because i just want to show you the difference between the two we're going to get into what is machine learning and all these things but i think just this overview right at the front about what a data science or machine learning life cycle kind of looks like is instructed all right so the important part here and i'll just key in on this uh just for brevity purposes is that much of what we think about when we we're doing software development we do construction and development of the actual software product it's all done in-house right so we do a lot of uh dedicated work in this kind of third step here right that's why i kind of circled it twice and then when it goes into release you you definitely maintain it right your bug your bug checking you're ensuring that the various components are doing the things that you want to do but in large part if you're rigorous in this step right what you hope is that nothing changes here in the out and the outcome right the difference between that process and what we think about in the data science life cycle is that much of what happens in the world of data science is totally unknown right until we actually put our models into deployment so that's a big difference certainly all of these things here are going to be you know very very important all the stuff here on the back end all right but in all honesty we don't want to know a whole lot about what happens to our models until we actually put them out into the world all right so this is a pretty big difference right and actually foreground's kind of everything that we think about when we think about machine learning because much of what we're going to talk about is like what are the conditions that work for machine learning do we have a really good question how do we track the metrics what are the risks associated with it all right all of this is calibrated and the reason these components are so important is because of this divergence in between these two concepts right we don't necessarily we do we build our data science products in-house but we don't really know how much utility they're going to provide us until we put them out into the world and because of that we have to be very specific about what questions we're asking how we know is working how we track these metrics right and then what are the risks that we can take right associated with how well this model works to answer our question all this is done in drift analysis model analysis model monitoring all of these processes are very specific and they're they're all derived based off what we've done kind of up here about how much well about how well we understand our models right kind of on the front end make this a little bit darker i think so with that all right let's move down into my version of the life cycle all right re-emphasizing the point here that everything is everything that we know about our models can be certainly created inside where we're developing them that won't really be able to validate it until we go out all right so we have these these four phases i know i've shown this to you before all right but we're going to talk about uh data science we're talking about machine learning in the context of these four phases in particular the first three all right because that much of the class kind of focuses on these first three we have other classes that focus more on this all right but what we're going to talk about is kind of through these first three phases of deployment and also it's it's just hard to get to all of these so we're going to focus on the first three all right and the machine learning overview is going to cover kind of the nature of the things you need to know in the context of those first three phases all right those being idea development data prep and problem exploration and then problem solution all right and then in this week's this week's class we're going to focus on idea development it could be a series of questions you should be asking every time you're presented with a data science or machine machine learning in particular problem all right and it's a subset of the potential questions you should ask all right so now what is machine learning all right so let's get into it all right let's talk about what is machine learning and how it's used again i apologize still a little still a little sick here all right so these are some famous quotes all right from very well known computer scientists or founders of of the machine learning field mitchell goodfellow and samuel uh you could read these to yourselves but you know in general i think the first one probably you know spells it out probably the best it just gives the computers an ability to learn without explicitly being programmed right being told exactly what to do right the quote down on the bottom all right is a sort of more kind of a technical way to look at it in terms of just the experience and the sets of tasks and then the outcomes it can actually be kind of mathematically defined through these different parameters all right right but the idea is that we give it a general set of constraints all right and then the machine learns patterns this is what good fellow is talking about here learns the patterns inside the data given these constraints and then generalizes the results onto new data into data has not been seen all right we'll talk through a lot of these right as we get into this portion of the class all right so machine versus human there's a whole list of things that humans are really good at and machines are really good at i think the these are kind of obvious on their face all right calculations repetitive tests defined rules right computers are very good at that okay we defined what those are we give them to and so they can be automated right we're much better at understanding context thinking through problems asking the right questions setting tools and then most importantly interpreting the results okay and there's a reason that it kind of goes like this right over here so think about this is all the context with which we'll be doing in that first phase right we'll be understanding the context we're going to read through a case study this week you're going to have to understand the context of this marketing firm you're going to be looking at and then you're going to think through a problem you're going to ask the right questions you're going to potentially select tools all right but then once all that is done right then you can move over to kind of the machine oriented processes and let them take over but then at the end right when you have the results they still have to be interpreted back into all of this context all right no solutions live in a vacuum if you fully automate your processes and just give it over the machine learning uh or ai too it's just a matter of time before that starts to fail okay especially when you know the risk is certainly higher it's always better to have humans in the loop and this is why this important bullet here is kind of segmented down at the end because it's almost like a process right but we have to remember that humans are usually the ones that putting the problem back together computer's really good at breaking it apart we're better at interpreting the results okay so this is where we kind of live in the machine learning world in this area here all right so let's let's take a look at all the this is like a you know kind of a genealogy i guess a way to look at it as a classical machine learning you know kind of uh subclasses of different models right so now we're getting very specific into the models i mean there's there's another step right here it might be like semi-supervised or reinforcement but generally we have two really broad categories supervised and unsupervised the difference between these is very simple supervised has labels we know where the data comes from and we know what the target classes are and unsupervised does not all right and we're going to talk about this a little bit more detail here as i get into some examples but that's it i mean this is just categorized right this is not all right much of the advancements when we think of like in the ai systems or advances in technology all come from labeled data right so it's you have armies of intern somewhere labeling it whether it's a dog or a hot dog somewhere right we pass all those all those images in and a machine knows it or anything the same for ibm or the deep blue or the other really famous uh kind of ai machines that uh that you think of right they all learn to play these support games that all have very labeled data all right so the images the different patterns and potential ways that the board pieces or the chess pieces or the go pieces can lay is all defined right so that can all be learned in a very structured way all right as compared to unlabeled data uh we're still a very exciting area of machine learning but there's less less progress been made here generally when we think about kind of the advances of ai right here it's just we don't have labels right it might be that it's a whole block of text or a whole bunch of images that are labeled right or a whole bunch of numbers that don't necessarily have well-defined patterns right and then what was the responsibility of the machines is to identify those spanish right to put the patterns in there to put these things into more uh readable and understandable ways and learn a model around that okay whereas one might not be present okay here we'll have these very easy on this side kind of easy to predict think about your rows and columns like that and this would be much less structured all right so let's put this into into context right so here we're talking about pattern discovery right for supervised that's when we know right the inputs and the outputs are well known all right so we know a certain voter uh and that they're going to be affiliated with one particular right party or not right so we know what those labels are right does this voter might be a republican or a democrat all right do we know what those particular affiliation is unsupervised would be that we do not know what this particular voter is we just have characteristics of this particular person right but we don't know whether they're going to be a republican or a democrat and we were trying to predict that right it's to be discovered or the other thing would be like we wouldn't even know how many parties exist right we just wouldn't have that information like is there a way that we can model voter behavior in certain groups right assuming that we wouldn't even know that there were republicans are democrats so that would be the difference so here we just have a block of kind of characteristics where we were not sure what they would map to but up there we would know you know that they were just these kind of two-party affiliations right this is just a little more detailed kind of genealogy the same thing that we saw previously was supervised and unsupervised unsupervised is certainly broader than clustering so that's a little misleading but there are many different ways you can think of any all of text analysis is out here too so there's lots there's lots of broader categories we're going to spend most of our semester here in supervised we are going to do k-means we're going to go through that later in the semester all right we're not going to have labels we're going to try and do some clustering but for the most part uh we're going to stay in supervised and in classification all right so i'll show you some examples of of regression this is also a bit misleading because ensembles anti-system trees could do both classification or regression all right but uh we'll get into that in a little bit more detail but these are just some examples of how you know general models fall into kind of these broad categories all right so machine learning is a general use technology what does this mean all right let's think about this so generally used technology or a gdp there's a term there's a method that is invented that has enough protected aggregate impact across an economy to be able to be used in multi many different domains all right so you think about this from kind of the examples that we talked about i'm just gonna pause here for a second sorry about that i had to cough all right so when you think about the original examples that we did the first day of class right when we were trying to you know take a look at data science job postings they were all over the place right i don't have to reinforce this you guys get it well that's what we that's what we mean by that that's the reason that data science and particular machine learning in this example are uh so common right across all of these different professions right because it's a general use technology it can be used across a whole bunch of different industries all right so we think about and maybe this is you know given your the context of this class you don't have to be told this but you know the data is growing at just a ridiculous rate uh kind of continuously all right so if you click on this i don't know if you i have these slides in the collab so you should be able to click on this um apparently i can't click on this maybe i can anyway if you use this blanket or show kind of the um it'll show them by minute kind of utility uh use of twitter data i'll pull it up here i'm sure i can pull it up on this side hold on all right there we go let's pull this up so here we're seeing this is just a tweet sent just today you know pushing you know 550 000 you know this is uh tweets per day you know so neither say anyway just kind of a fun stat there pull it up and see where you're at on your end when you click on that but growing uh data availability at a crazy level error rates and imagenet if you're unfamiliar with image just a big set of images and errors mean that um you know the models that are being built to terms of classify the images there you know it's down from thirty percent 2010 to less than three percent today which is a big deal because anything less than five percent put a question there and i'll let you guys think about it just for a minute anyway i'll just give it away is uh less than human error so the average human error on these classification tests is about five percent so that means that the cnns are doing well anyway the models the neural networks i'm sure they're being developed there are doing better than humans but uh we also have to say to ourself okay well deep blue that a ibm ai machine searched two hundred and two hundred million potential chest positions all right per second and uh whereas kasparov was able to do no more than five to ten you know maybe per second you know per couple of seconds yet he almost played at the same level right there was even a point where i think they ran a draw it did eventually lose so why is that right why do we think that's the case all right so we think about these things as we go into kind of a machine learning overview all right and that one particular example would be important later so before we turn everything over to the robots we're really far away from what we consider a general intelligence right as compared to humans and machines cannot do anywhere close to a full range of tasks that humans could do maybe we all know that all right but there are conditions as a result of this that are suitable for machine learning all right so we call this sml all right so understanding machine learning i think it's important to understand these conditions which need to be present for it to work it's not a panacea there are some things that work really well and some things that in some conditions where it does so let's let's take a look at these all right so the important thing uh about machine learning right requires a very detailed level of specifications right what needs to be learned and data to support that right this includes engineering features through a series of trial and error right has to be kind of an experimental process right where you keep going back and forth through development of features developing of models and then coming back and seeing if the results have improved and typically too and this is kind of more of a meta concept for everyone is that it has to be in order for it to work at least where i've seen it outside of research context where you do these kind of one-offs it really has to be embedded in kind of normal practices right so if you have like this fringe organization inside your company that's trying to apply machine learning it it typically won't work right so you have to have a culture where it really invests maybe that's less important right now for the context but it is a reality right so let's take let's take let's take a step back here and we'll talk about some more specifics all right all right so we talked about this one learning functions need to be mapped and inputs to outputs all right so we have to be clear understanding that our data can predict what we wanted to predict you typically need a large amount of data all right much more than you would need for inferential or kind of sample based statistics right much of the field of statistics was based off kind of small sample sets right small ends machine learning is based off large heads you have to have a significant amount of data typically for it to work this one test number three is also related to or item number three related to item number one right usually there has to be kind of clear feedback right definable goals and metrics you have to know what you are going to achieve all right and you have to know whether you're getting there or not okay this gets back to kind of understanding your business question and metrics so you can say whether a certain whether your model is doing what you want it to do whether it's actually providing the value that you hope that it does all right reasoning a diverse background this is kind of our philosophical one here all right you know no machine learning process is going to understand like the political dynamics in the south china sea just not going to know that all right so it needs to be kind of do it has to be fairly fairly simple in all fairness all right all right and then this one may be a little bit more controversial um you know why the decision was made does not necessarily need to be clear all right so we think i'll explain more about this but when you think about um the way that uh most machine learning algorithms work it's not true of all i've actually made a lot of private progress on this right in terms of just where um you know explainable ai things like that but still uh you know your neural network might use millions of numerical weights in order to do some type of classification unpacking that is can be quite difficult right so uh using you know machine learning in a space where you have to have to really understand which variables are contributing and why it's not always not always great all right a tolerance for sub-optimal solutions all right this is true uh i don't know i put a question mark this is true of most models we have to just really understand you know what's going on inside our insider machine learning model all right because typically there's always going to be a certain amount of percentage error that we're going to have and once we put these in and we empower them for making choices for us it's just really important to understand uh where those choices could go wrong all right all right and it should be that that doesn't change rapidly over time all right there's ways to get around this all right you can imagine you know the preferences associated with netflix content as an example is changing so quickly but the way to get around is just reaching they just retrain their algorithms every 24 hours they're constantly training and constantly learning um which is very expensive all right so but the idea behind you know way most people use machine learning is that the data that they're going to use wouldn't necessarily be changing incredibly quickly right it'd be somewhat stable um inputs right that way you can also track and see how well it's doing in the real world right if that data stream is fairly stable right but many times it's not all right so those are the conditions all right so again part of this is not to dissuade you that machine learning isn't having a huge impact or ai has a huge impact it has right it definitely has but i think people approach it just as a one-size-fits-all type of solution it's really not that okay it's really there has to be these conditions at least in an ideal world now some of them could be bent you know this is the matrix rules can be broken but uh those are the ones that make for the conditions to be ideal right for this to work all right okay so let's just talk about how machines do this learning how does it happen all right there's not only three high level parts this is an oversimplification but uh as the benefit of being true right so we have our data input all right we have a level of abstraction of that data all right and then we have a generalization of that abstraction all right so this is past date all right so going back to the beginning here data input all right it's information that can be utilized as a basis for future decision making all right so put that in the context of the other criteria inputs have to match to outputs all right but this is the data we can use to predict in the future all right most of machine learning if not all of machine learning is dedicated towards prediction right we want to figure out what's going on in the future all right so this input data that we have that we know could potentially right should potentially be able to predict kind of some event in the in the future is represented in a broader way right using an algorithm all right so we have it down here in kind of the weeds you can think about it and then the algorithm kind of pulls it up in a broader way all right and develops a you know memory about it right understands the patterns learns the patterns and then this is generalized oops all right and then the abstract the abstracted representation is generalized to form a framework of decision making all right so that just means like when new data comes in all right whatever that model that has been learned right this this model right can then be generalized to make predictions all right so just regardless of what's happened in the past that training data is learned the new data comes in we use that past information to kind of generalize about what we're going to do in the future this is just a terrible like a copy copy and paste from that same book that i referenced above but we think about our data here right this is the process of developing and gathering and putting the data this is the machine learning development process right and this is putting it into deployment right it's not not that different than any other type of model all right we just have to say to ourselves you know what level of abstraction and generalization do we accept you know or what is the risk associated with the type of question that we're asking all right because it could be that we just abstract too far away right and that when we go to generalize it to new data we have really big error terms right so there's a balance here uh and let me let me just reticulate it re-articulate all right the kind of three-phase process all right so here when we think about kind of this very high level data you know abstraction the generalization we think about kind of this is our data process right we're gathering and acquiring the data all right and then in these two phases right we're kind of generalizing for the most part right or i'm sorry we're doing kind of abstraction right all right we're taking that data and we're trying to fit it into a model that can be used for new data for generalization which is when we put it out into into the world right and expose it to new data that it hasn't seen yet but sorry okay so let's get into terms and phrases all right uh methods and terms that's very high level right so uh you know to to encapsulate all this the way that i'm going to they're going to approach the class to get you guys immersed into what is machine learning is to work through terms and phrases and concepts in each one of these phases of the machine learning process right in this idea development this data prep and exploration and solution development all right so we're going to work through and each over the next three weeks we're going to focus on terms of concepts from each one of these steps along the way all right so some of the first ones here that we're going to dive into is idea development in the idea development category well anyway you can read them here and go through each one of these in detail and then the next space we're going to do data data prep and problem expiration and then finally solution development right and then for the rest of the semester we're going to take all these concepts and put them all together and learn several different models but after which before which by working through these we should have a solid foundation in exactly what we're talking about we'll be able to speak the same language of machine learning and then we'll move forward all right okay so i'm going to stop right there and i'm going to do a separate uh little video for because this one's already going pretty long do a separate video for phase one all right so this is 25 minutes here uh but this is a very high level overview of machine learning generally all right we'll get into more details about what some of these terms mean as it relates to machine learning in phase one