{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Initiation",
   "id": "83c947a007cad28d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:07.124617Z",
     "start_time": "2025-02-10T23:21:03.463845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
   ],
   "id": "ddfc3040225af5c0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the Necessary API Keys",
   "id": "850f3e0ff70af3f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:07.949878Z",
     "start_time": "2025-02-10T23:21:07.942705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "huggingface_api_key = os.getenv(\"hugging_face_key\")\n",
    "pinecone_key = os.getenv(\"pinecone_api_key\")\n",
    "mongo_uri = os.getenv(\"mongo_db_key\")\n",
    "open_ai_key = os.getenv(\"open_ai_api_key\")\n"
   ],
   "id": "445467849134e21d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set-up/Connect to Pinecone",
   "id": "716b6d3055e0e9d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:09.908956Z",
     "start_time": "2025-02-10T23:21:08.844804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create index\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_key)\n",
    "index_name = \"rag-app-images\"\n",
    "\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension=512,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud = \"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "#vector_store = PineconeVectorStore(embedding=embeddings, index=index)"
   ],
   "id": "2d87d8c5dce624bb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:10.425555Z",
     "start_time": "2025-02-10T23:21:10.347778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "from huggingface_hub import whoami\n",
    "\n",
    "login(huggingface_api_key)\n",
    "whoami()"
   ],
   "id": "10e2863a8ad23085",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'user',\n",
       " 'id': '66d5147ab005ad82ca47182f',\n",
       " 'name': 'dorukozar',\n",
       " 'fullname': 'Doruk Ozar',\n",
       " 'email': 'dorukozar@gmail.com',\n",
       " 'emailVerified': True,\n",
       " 'canPay': False,\n",
       " 'periodEnd': None,\n",
       " 'isPro': False,\n",
       " 'avatarUrl': '/avatars/06335824f9a6991ec7b901b31802dd5b.svg',\n",
       " 'orgs': [],\n",
       " 'auth': {'type': 'access_token',\n",
       "  'accessToken': {'displayName': 'Presentation',\n",
       "   'role': 'read',\n",
       "   'createdAt': '2025-01-16T00:00:59.134Z'}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:12.320965Z",
     "start_time": "2025-02-10T23:21:10.857335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ],
   "id": "fbe76ebc37081441",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:13.142046Z",
     "start_time": "2025-02-10T23:21:12.782016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create index\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_key)\n",
    "index_name = \"rag-app\"\n",
    "\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud = \"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index_text = pc.Index(index_name)\n",
    "\n",
    "vector_store_text = PineconeVectorStore(embedding=huggingface_embeddings, index=index_text)"
   ],
   "id": "2d1a513e1f6c997e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:16.134171Z",
     "start_time": "2025-02-10T23:21:13.222267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_query = \"What is supervised and unsupervised machine learning?\"\n",
    "retriever = vector_store_text.as_retriever(search_kwargs={\"k\":5})\n",
    "# retriever.get_relevant_documents(query)\n",
    "retrieved_docs = retriever.invoke(user_query)\n",
    "retrieved_docs"
   ],
   "id": "73d668c8639195bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3fa65848-c8ee-43e9-8856-541127519cf5', metadata={'source_id': 'ML_Overview.txt'}, page_content=\"getting very specific into the models i mean there's there's another step right here it might be like semi-supervised or reinforcement but generally we have two really broad categories supervised and unsupervised the difference between these is very simple supervised has labels we know where the data comes from and we know what the target classes are and unsupervised does not all right and we're going to talk about this a little bit more detail here as i get into some examples but that's it i mean this is just categorized right this is not all right much of the advancements when we think of like in the ai systems or advances in technology all come from labeled data right so it's you have armies of intern somewhere labeling it whether it's a dog or a hot dog somewhere right we pass all those all those images in and a machine knows it or anything the same for ibm or the deep blue or the other really famous uh kind of ai machines that uh that you think of right they all learn to play\"),\n",
       " Document(id='d430a942-eb49-4161-b6d2-6928625bc72e', metadata={'source_id': 'TheElementsofStatisticalLearningDataMining,InferenceandPrediction'}, page_content='of each of the variables.\\nAs discussed above, unsupervised learning is concerned with revealing\\nproperties of the data density g(x). Each technique focuses on a particu-\\nlar property or set of properties. Although this approach of transforming\\nthe problem to one of supervised learning (14.10)–(14.14) seems to have\\nbeen part of the statistics folklore for some time, it does not appear to\\nhave had much impact despite its potential to bring well-developed su-\\npervised learning methodology to bear on unsupervised learning problems.\\nOne reason may be that the problem must be enlarged with a simulated\\ndata set generated by Monte Carlo techniques. Since the size of this data\\nset should be at least as large as the data sample N0 ≥N, the compu-\\ntation and memory requirements of the estimation procedure are at least\\ndoubled. Also, substantial computation may be required to generate the\\nMonte Carlo sample itself. Although perhaps a deterrent in the past, these'),\n",
       " Document(id='a389a54a-1f83-4c9c-a1dd-236653d10f6a', metadata={'source_id': 'Clustering_4.22.txt'}, page_content=\"okay so uh this morning we're going to talk about what this morning during this video we're going to talk about unsupervised machine learning that has us over here you guys have seen this slide before we've been mostly doing supervised already k n and we did decision trees but now we're going to move into unsupervised which as a reminder means you know we just don't have any labels all right no labels on the data that means we have to identify these patterns without necessarily a target to match them to okay so the one approach that we're going to use in this and there are many is is clustering and that's a pretty large space as well but we're going to do k-means which is actually something we've seen before if you remember we walked through this example right where we have a random string of numbers and the ideas that we need to maximize the distance between these two clusters right we're saying we have two clusters and so we keep trading the numbers back and forth right between the\"),\n",
       " Document(id='75538974-44c3-4fbd-9f7b-58dfc1cba198', metadata={'source_id': 'Clustering_4.22.txt'}, page_content=\"materials on top of it but they didn't realize it was going to look like this ahead of time that's the idea behind unsupervised machine learning you don't really know what you don't know right you don't know what it's going to look like up front and then when you get it it requires a bit of a qualitative interpretation like what does this necessarily mean like okay so we see these groups great but what's going on there all right and that's where kind of uh your subject matter expertise starts to come in or you have to dig deeper into what exactly is you know what do these clusters mean you know how can we look at the different variables that are composing them and then uh and start to develop a strategy around them all right so in a lot of ways i think this is fair unsupervised machine learning is much more complicated than supervised machine learning because it requires kind of you know multiple steps along the way right we do all the same data preparation you know we build the\"),\n",
       " Document(id='b456f18f-a877-422e-b2b5-1f95b1d1e4f0', metadata={'source_id': 'Overview_ML_and_Clustering_InClass_3.21'}, page_content='Machine Learning Overview, EDA and Clustering\\nBrian Wright\\nbrianwright@virginia.edu1. What is Machine Learning ?\\n2. What is exploratory data analysis?\\n3. k-means clustering\\n– Does Congress vote in patterns?\\n4. Multi-dimensional k-means clustering\\n– Are NBA players compensated according to performance?\\nOutline: Intro to Unsupervised ML\\n2“A field of Computer Science that gives computers the ability to learn\\nwithout being explicitly programmed.”\\n-\\nArthur Samuel (Coined the term in 1959 at IBM)\\n“The ability [for systems] to acquire their own knowledge, by\\nextracting patterns from raw data.”\\n-\\nDeep Learning, Goodfellow et alMachine vs. human\\nMachine\\nHuman\\nUnderstanding context\\n✔\\nThinking through the problem\\n✔\\nAsking the right questions\\n✔\\nSelecting the right tools\\n✔\\nPerforming calculations quickly\\n✔\\nPerforming repetitive tasks\\n✔\\nFollowing pre-defined rules\\n✔\\nInterpreting results\\n✔5Pattern discovery when inputs (x) and outputs (y) are known\\nSupervised machine learning\\nInput x:\\nVoter\\nOutput y:')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:16.818198Z",
     "start_time": "2025-02-10T23:21:16.814275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "print(format_docs(retrieved_docs))"
   ],
   "id": "236fb65fb085b2e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting very specific into the models i mean there's there's another step right here it might be like semi-supervised or reinforcement but generally we have two really broad categories supervised and unsupervised the difference between these is very simple supervised has labels we know where the data comes from and we know what the target classes are and unsupervised does not all right and we're going to talk about this a little bit more detail here as i get into some examples but that's it i mean this is just categorized right this is not all right much of the advancements when we think of like in the ai systems or advances in technology all come from labeled data right so it's you have armies of intern somewhere labeling it whether it's a dog or a hot dog somewhere right we pass all those all those images in and a machine knows it or anything the same for ibm or the deep blue or the other really famous uh kind of ai machines that uh that you think of right they all learn to play\n",
      "\n",
      "of each of the variables.\n",
      "As discussed above, unsupervised learning is concerned with revealing\n",
      "properties of the data density g(x). Each technique focuses on a particu-\n",
      "lar property or set of properties. Although this approach of transforming\n",
      "the problem to one of supervised learning (14.10)–(14.14) seems to have\n",
      "been part of the statistics folklore for some time, it does not appear to\n",
      "have had much impact despite its potential to bring well-developed su-\n",
      "pervised learning methodology to bear on unsupervised learning problems.\n",
      "One reason may be that the problem must be enlarged with a simulated\n",
      "data set generated by Monte Carlo techniques. Since the size of this data\n",
      "set should be at least as large as the data sample N0 ≥N, the compu-\n",
      "tation and memory requirements of the estimation procedure are at least\n",
      "doubled. Also, substantial computation may be required to generate the\n",
      "Monte Carlo sample itself. Although perhaps a deterrent in the past, these\n",
      "\n",
      "okay so uh this morning we're going to talk about what this morning during this video we're going to talk about unsupervised machine learning that has us over here you guys have seen this slide before we've been mostly doing supervised already k n and we did decision trees but now we're going to move into unsupervised which as a reminder means you know we just don't have any labels all right no labels on the data that means we have to identify these patterns without necessarily a target to match them to okay so the one approach that we're going to use in this and there are many is is clustering and that's a pretty large space as well but we're going to do k-means which is actually something we've seen before if you remember we walked through this example right where we have a random string of numbers and the ideas that we need to maximize the distance between these two clusters right we're saying we have two clusters and so we keep trading the numbers back and forth right between the\n",
      "\n",
      "materials on top of it but they didn't realize it was going to look like this ahead of time that's the idea behind unsupervised machine learning you don't really know what you don't know right you don't know what it's going to look like up front and then when you get it it requires a bit of a qualitative interpretation like what does this necessarily mean like okay so we see these groups great but what's going on there all right and that's where kind of uh your subject matter expertise starts to come in or you have to dig deeper into what exactly is you know what do these clusters mean you know how can we look at the different variables that are composing them and then uh and start to develop a strategy around them all right so in a lot of ways i think this is fair unsupervised machine learning is much more complicated than supervised machine learning because it requires kind of you know multiple steps along the way right we do all the same data preparation you know we build the\n",
      "\n",
      "Machine Learning Overview, EDA and Clustering\n",
      "Brian Wright\n",
      "brianwright@virginia.edu1. What is Machine Learning ?\n",
      "2. What is exploratory data analysis?\n",
      "3. k-means clustering\n",
      "– Does Congress vote in patterns?\n",
      "4. Multi-dimensional k-means clustering\n",
      "– Are NBA players compensated according to performance?\n",
      "Outline: Intro to Unsupervised ML\n",
      "2“A field of Computer Science that gives computers the ability to learn\n",
      "without being explicitly programmed.”\n",
      "-\n",
      "Arthur Samuel (Coined the term in 1959 at IBM)\n",
      "“The ability [for systems] to acquire their own knowledge, by\n",
      "extracting patterns from raw data.”\n",
      "-\n",
      "Deep Learning, Goodfellow et alMachine vs. human\n",
      "Machine\n",
      "Human\n",
      "Understanding context\n",
      "✔\n",
      "Thinking through the problem\n",
      "✔\n",
      "Asking the right questions\n",
      "✔\n",
      "Selecting the right tools\n",
      "✔\n",
      "Performing calculations quickly\n",
      "✔\n",
      "Performing repetitive tasks\n",
      "✔\n",
      "Following pre-defined rules\n",
      "✔\n",
      "Interpreting results\n",
      "✔5Pattern discovery when inputs (x) and outputs (y) are known\n",
      "Supervised machine learning\n",
      "Input x:\n",
      "Voter\n",
      "Output y:\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embed the query",
   "id": "2e2b8c59dea09d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:18.369874Z",
     "start_time": "2025-02-10T23:21:18.319020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = clip_processor(text=[user_query], return_tensors=\"pt\", padding=True)\n",
    "text_embedding = clip_model.get_text_features(**inputs).detach().numpy().tolist()[0]"
   ],
   "id": "87a06198d92826bf",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Query the Pinecone vector db and return top 5 matches",
   "id": "4fafe291424f1c99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:19.472625Z",
     "start_time": "2025-02-10T23:21:19.359418Z"
    }
   },
   "cell_type": "code",
   "source": "query_results = index.query(vector=text_embedding, top_k=5, include_metadata=True)",
   "id": "ad6971ecde8670d6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:20.407070Z",
     "start_time": "2025-02-10T23:21:20.404030Z"
    }
   },
   "cell_type": "code",
   "source": "query_results[\"matches\"]",
   "id": "e76cdfc92d9ad6bf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '3001_ETA/page_9_img_2.png',\n",
       "  'metadata': {'file_name': '3001_ETA', 'image_key': 'page_9_img_2.png'},\n",
       "  'score': 0.334317118,\n",
       "  'values': []},\n",
       " {'id': 'machine_learning_bootcamp_II/page_8_img_1.png',\n",
       "  'metadata': {'file_name': 'machine_learning_bootcamp_II',\n",
       "               'image_key': 'page_8_img_1.png'},\n",
       "  'score': 0.322387815,\n",
       "  'values': []},\n",
       " {'id': 'machine_learning_overview/page_8_img_1.png',\n",
       "  'metadata': {'file_name': 'machine_learning_overview',\n",
       "               'image_key': 'page_8_img_1.png'},\n",
       "  'score': 0.322387815,\n",
       "  'values': []},\n",
       " {'id': 'machine_learning_III/page_8_img_1.png',\n",
       "  'metadata': {'file_name': 'machine_learning_III',\n",
       "               'image_key': 'page_8_img_1.png'},\n",
       "  'score': 0.322387815,\n",
       "  'values': []},\n",
       " {'id': 'machine_learning_bootcamp_II copy/page_8_img_1.png',\n",
       "  'metadata': {'file_name': 'machine_learning_bootcamp_II copy',\n",
       "               'image_key': 'page_8_img_1.png'},\n",
       "  'score': 0.322387815,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Connect to Mongodb",
   "id": "8d92e0000c8d1050"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:21.825533Z",
     "start_time": "2025-02-10T23:21:21.657004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pymongo import MongoClient\n",
    "import gridfs\n",
    "\n",
    "client = MongoClient(mongo_uri)\n",
    "\n",
    "#client = MongoClient(MONGO_URI)\n",
    "\n",
    "db = client[\"images\"]\n",
    "\n",
    "collection = db[\"images_for_rag\"]\n",
    "\n",
    "print(\"Connected to MongoDB successfully!\")"
   ],
   "id": "8af376f705e4db3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB successfully!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:22.863281Z",
     "start_time": "2025-02-10T23:21:22.860583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_names_list = os.listdir(\"data_processed\")\n",
    "\n",
    "fs = gridfs.GridFS(db)\n",
    "\n"
   ],
   "id": "3733ade1dcfdc1f6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Query MongDB",
   "id": "43b34bcd62d43dc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:25.845834Z",
     "start_time": "2025-02-10T23:21:24.072110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# image_data = fs.find_one({\"filename\": \"clustering.png\"})\n",
    "image_data_list = []\n",
    "for i in query_results[\"matches\"]:\n",
    "    filename = i[\"id\"]\n",
    "    image_data = fs.find_one({\"filename\": filename})\n",
    "    image_data_list.append(image_data)"
   ],
   "id": "2edaa7fcdf7d18a5",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:26.333765Z",
     "start_time": "2025-02-10T23:21:26.329184Z"
    }
   },
   "cell_type": "code",
   "source": "image_data_list",
   "id": "52c4ada0555646ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<gridfs.synchronous.grid_file.GridOut at 0x1bb7c7d30>,\n",
       " <gridfs.synchronous.grid_file.GridOut at 0x1bda55e40>,\n",
       " <gridfs.synchronous.grid_file.GridOut at 0x1bda55990>,\n",
       " <gridfs.synchronous.grid_file.GridOut at 0x1bda55ed0>,\n",
       " <gridfs.synchronous.grid_file.GridOut at 0x1bda55e70>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:28.661599Z",
     "start_time": "2025-02-10T23:21:28.642496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image, ImageChops\n",
    "import io\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def images_are_equal(img1, img2):\n",
    "    \"\"\"Check if two images are identical pixel by pixel.\"\"\"\n",
    "    return ImageChops.difference(img1, img2).getbbox() is None\n",
    "\n",
    "def hash_image(image):\n",
    "    \"\"\"Compute hash of an image.\"\"\"\n",
    "    hasher = hashlib.md5()\n",
    "    hasher.update(image.tobytes())  # Convert image to bytes and hash\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def images_are_similar(img1, img2, threshold=0.7):\n",
    "    \"\"\"Compare two images using SSIM after resizing them to the same dimensions.\"\"\"\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    img1_gray = img1.convert('L')\n",
    "    img2_gray = img2.convert('L')\n",
    "\n",
    "    # Resize images to the same size\n",
    "    common_size = (min(img1_gray.width, img2_gray.width), min(img1_gray.height, img2_gray.height))\n",
    "    img1_resized = img1_gray.resize(common_size, Image.LANCZOS)\n",
    "    img2_resized = img2_gray.resize(common_size, Image.LANCZOS)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    img1_np = np.array(img1_resized)\n",
    "    img2_np = np.array(img2_resized)\n",
    "\n",
    "    # Compute SSIM similarity\n",
    "    similarity = ssim(img1_np, img2_np)\n",
    "    print(similarity)\n",
    "    return similarity > threshold  # Return True if similar"
   ],
   "id": "afff6c6b36f31186",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:35.802157Z",
     "start_time": "2025-02-10T23:21:32.359656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image, ImageChops\n",
    "import io\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "\n",
    "if len(image_data_list)>0:\n",
    "    local_image_list = []\n",
    "    hashes = set()\n",
    "    user_input = input(\"\"\"\n",
    "    To use similarity, enter the number 1\n",
    "    To use hashing comparison, enter the number 2\n",
    "    To use pixel to pixel comparison, enter the number 3\n",
    "    \"\"\")\n",
    "    \n",
    "    for j in image_data_list:\n",
    "        if j:\n",
    "            # Convert binary data to a PIL Image\n",
    "            image = Image.open(io.BytesIO(j.read()))\n",
    "            \n",
    "            if user_input.strip() == \"1\":\n",
    "                duplicate_found = False\n",
    "                for stored_image in local_image_list:\n",
    "                    if images_are_similar(stored_image, image):\n",
    "                        print(f\"⚠️ Similar image found at index {j}\")\n",
    "                        duplicate_found = True\n",
    "                        break\n",
    "        \n",
    "                if not duplicate_found:\n",
    "                    local_image_list.append(image)\n",
    "                    image.show()\n",
    "            \n",
    "            elif user_input.strip() == \"2\":\n",
    "                img_hash = hash_image(image)\n",
    "                if img_hash in hashes:\n",
    "                    print(f\"⚠️ Duplicate image found at index {j}\")\n",
    "                else:\n",
    "                    hashes.add(img_hash)\n",
    "                    image.show()\n",
    "            \n",
    "            elif user_input.strip() == \"3\":\n",
    "                duplicate_found = False\n",
    "                for stored_image in local_image_list:\n",
    "                    if images_are_equal(stored_image, image):\n",
    "                        print(f\"⚠️ Duplicate image found at index {j}\")\n",
    "                        duplicate_found = True\n",
    "                        break\n",
    "    \n",
    "                if not duplicate_found:\n",
    "                    local_image_list.append(image)\n",
    "                    image.show()\n",
    "            else:\n",
    "                print(\"Wrong input!\")\n",
    "                sys.exit(1)\n",
    "            \n",
    "            \n",
    "            # Display the image\n",
    "            # image.show()\n",
    "        else:\n",
    "            print(\"❌ Image not found\")\n",
    "            \n",
    "            \n"
   ],
   "id": "e05e5d96b152baf5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7365119420482111\n",
      "⚠️ Similar image found at index <gridfs.synchronous.grid_file.GridOut object at 0x1bda55e40>\n",
      "0.7365119420482111\n",
      "⚠️ Similar image found at index <gridfs.synchronous.grid_file.GridOut object at 0x1bda55990>\n",
      "0.7365119420482111\n",
      "⚠️ Similar image found at index <gridfs.synchronous.grid_file.GridOut object at 0x1bda55ed0>\n",
      "0.7365119420482111\n",
      "⚠️ Similar image found at index <gridfs.synchronous.grid_file.GridOut object at 0x1bda55e70>\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:21:38.973990Z",
     "start_time": "2025-02-10T23:21:38.970399Z"
    }
   },
   "cell_type": "code",
   "source": "local_image_list",
   "id": "d0d3f32ee452cb2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1300x917>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "break\n",
    "---"
   ],
   "id": "1e015c8e9a01b01e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embedding text and image at the same time",
   "id": "a025521686269183"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:31:47.025527Z",
     "start_time": "2025-02-10T23:31:47.005257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "encoded_images = []\n",
    "count = 0\n",
    "\n",
    "if len(image_data_list) > 0:\n",
    "    for j in local_image_list:\n",
    "        if j:\n",
    "            print(f\"Processing image {count + 1}\")\n",
    "            \n",
    "            try:\n",
    "                # Ensure the file pointer is at the start\n",
    "                j.seek(0)\n",
    "                \n",
    "                \n",
    "                # Convert to PNG format and encode\n",
    "                buffered = io.BytesIO()\n",
    "                j.save(buffered, format=\"JPEG\")\n",
    "                \n",
    "                encoded_image = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "                encoded_images.append(encoded_image)\n",
    "                \n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error processing image {count + 1}: {e}\")\n",
    "        else:\n",
    "            print(\"❌ Image not found\")\n",
    "\n",
    "# Closing file handlers\n",
    "for img in image_data_list:\n",
    "    img.close()\n",
    "\n",
    "# Displaying the number of successfully encoded images\n",
    "print(f\"✅ Successfully encoded {count} images.\")\n"
   ],
   "id": "d19b676a2b6e657c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1\n",
      "✅ Successfully encoded 1 images.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:32:04.005160Z",
     "start_time": "2025-02-10T23:32:04.000434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prompt = f\"\"\"You are an expert LLM assistant specialized in answering questions related to computer science/data science/machine learning/LLM. Use the retrieved information from RAG (Retrieved information and Image Descriptions) and your knowledge to respond accurately and clearly to each question.\n",
    "# \n",
    "# Guidelines:\n",
    "# 1. Provide concise and informative answers.\n",
    "# 2. If the question is beyond the scope of your knowledge or the provided information, state, \"I don't know.\"\n",
    "# 3. If the context section (the information that is returned by RAG pipeline) has no information about a part of the question, please express that \"The retrieved information did not contain answer to this question\" but if you can answer it based on your knowledge please do\n",
    "# 4. Use examples where applicable to illustrate your answers.\n",
    "# 5. Maintain a professional and helpful tone.\n",
    "# \n",
    "# Question: {user_query}\n",
    "# \n",
    "# Retrieved Information: {format_docs(retrieved_docs)}\n",
    "# \n",
    "# Answer:\n",
    "# \"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Guidelines:\n",
    "1. Provide extensive and informative answers.\n",
    "2. If the question is beyond the scope of your knowledge or the provided information, state, \"I don't know.\"\n",
    "3. If the context section (the information that is returned by RAG pipeline) has no information about a part of the question, please express that \"The retrieved information did not contain answer to this question\" but if you can answer it based on your knowledge please do\n",
    "4. Use examples where applicable to illustrate your answers.\n",
    "5. Maintain a professional and helpful tone.\n",
    "\n",
    "Question: {user_query}\n",
    "\n",
    "Retrieved Information: {format_docs(retrieved_docs)}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n"
   ],
   "id": "d6a6682fcf296401",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:32:04.489116Z",
     "start_time": "2025-02-10T23:32:04.486668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content = [{\"type\":\"text\", \"text\":prompt}]\n",
    "for img in encoded_images:\n",
    "    content.append({\n",
    "        \"type\":\"image_url\",\n",
    "        \"image_url\":{\n",
    "            \"url\":f\"data:image/jpeg;base64, {img}\"\n",
    "        }\n",
    "    })"
   ],
   "id": "2ef7707bc5b04715",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:32:20.413004Z",
     "start_time": "2025-02-10T23:32:05.297814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=open_ai_key)\n",
    "\n",
    "try:\n",
    "    chat = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\":\"system\",\n",
    "            \"content\":\"You are an expert LLM assistant specialized in answering questions related to computer science/data science/machine learning/LLM. Use the retrieved information from RAG (Retrieved information and Image Descriptions) and your knowledge to respond accurately and clearly to each question.\"\n",
    "        },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(chat.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "id": "cd493e60e9c5df84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised and unsupervised learning are two fundamental approaches in machine learning, each designed to address different types of tasks.\n",
      "\n",
      "### Supervised Learning\n",
      "\n",
      "**Definition:**\n",
      "Supervised learning involves training a model on a labeled dataset, meaning that each training example is paired with an output label. The aim is to learn the mapping from inputs to outputs to predict labels for new, unseen data.\n",
      "\n",
      "**How It Works:**\n",
      "- **Input**: A set of input features \\(X\\).\n",
      "- **Output**: A known label \\(Y\\), which is what the model attempts to predict.\n",
      "- **Goal**: Learn a function \\(f(X) = Y\\) that can map inputs to outputs.\n",
      "- **Examples**: \n",
      "  - **Classification**: Predicting a category. For example, email spam detection (spam or not spam).\n",
      "  - **Regression**: Predicting a continuous value. For instance, predicting house prices based on features like size and location.\n",
      "\n",
      "**Applications:**\n",
      "Supervised learning is widely used in applications where past observations with known outcomes are available, such as fraud detection, risk assessment, and personalized recommendations.\n",
      "\n",
      "### Unsupervised Learning\n",
      "\n",
      "**Definition:**\n",
      "Unsupervised learning deals with data that does not have labeled responses. The model attempts to identify patterns, structures, or relationships within the data.\n",
      "\n",
      "**How It Works:**\n",
      "- **Input**: A set of input features \\(X\\) without associated labels.\n",
      "- **Goal**: Discover the underlying structure, such as clusters or associations, within the data.\n",
      "- **Examples**:\n",
      "  - **Clustering**: Grouping similar data points together. An example is customer segmentation based on purchasing behavior.\n",
      "  - **Association**: Discovering relationships between variables. For instance, market basket analysis in retail to identify products frequently bought together.\n",
      "\n",
      "**Challenges:**\n",
      "Unsupervised learning can be more complex because it requires qualitative interpretation and the outcome is not always clear compared to supervised tasks.\n",
      "\n",
      "**Applications:**\n",
      "Unsupervised learning is useful in exploratory data analysis, anomaly detection, and dimensionality reduction tasks where the aim is to gain insights into the data structure.\n",
      "\n",
      "### Key Differences\n",
      "\n",
      "- **Labeling**: Supervised learning requires labeled data while unsupervised learning does not.\n",
      "- **Objective**: Supervised learning aims to predict outputs for new data, while unsupervised learning seeks to identify hidden patterns or groupings.\n",
      "- **Examples**: Supervised examples include classification and regression tasks, whereas unsupervised examples include clustering and association.\n",
      "\n",
      "In summary, the primary distinction lies in the presence or absence of labels in the dataset and the nature of the task being accomplished. Each approach has its unique benefits and applications, and the choice between them depends on the problem at hand and the availability of labeled data.\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
